# Movie-recomendation-System
This project combines computer vision, emotion recognition, and movie recommendation to create a dynamic and interactive system that suggests movies based on the user's facial expression. The system uses a combination of libraries and tools like DeepFace for emotion detection, OpenCV for real-time video capture, and pandas for movie data processing. The main goal is to analyze the user's facial expressions using the webcam, detect emotions, and recommend movies accordingly. 

The process starts by capturing an image from the webcam. In the background, the DeepFace library analyzes the captured image to determine the dominant emotion, such as happy, sad, neutral, surprised, etc. The model processes the image, detecting facial landmarks and interpreting the emotion based on predefined criteria. Once the emotion is identified, the program uses a simple mapping system to associate that emotion with a particular genre of moviesâ€”comedy for happiness, romance for sadness, drama for neutrality, and adventure for surprise Fear for Thriller.

Next, the system reads a movie dataset stored in a CSV file, where each movie has a genre assigned. When an emotion is detected, the system filters the movies based on the genre associated with the emotion and recommends a list of movies that match. For example, if the detected emotion is "neutral," it will suggest drama movies. This is done by checking the movie dataset for entries that match the corresponding genre.

Additionally, the dataset can be adjusted to accommodate different genre names by updating the code to reflect the actual column names in the dataset. If the emotion is not mapped correctly, or no movies are found for the detected emotion, the system will notify the user and return a message indicating no suitable recommendations were found.

The system's strength lies in its real-time feedback loop, which allows users to interact with it through facial expressions. It is an exciting application of artificial intelligence (AI) in entertainment and can be expanded to other use cases such as personalized recommendations for books, music, or even video games based on mood detection. This combination of AI and user interaction makes it a highly engaging and dynamic tool for improving user experience through personalized content delivery.

Overall, this project demonstrates how powerful AI technologies like emotion detection and recommendation systems can be used together to create a more personalized experience. It also highlights the flexibility of deep learning models like DeepFace, which are capable of real-time emotion recognition and can be integrated with other tools for practical applications. The project is also a great example of how Python, with libraries such as OpenCV, DeepFace, and pandas, can be used to bring real-time interactive systems to life.

